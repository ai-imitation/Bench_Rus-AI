{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca94b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "dotenv = dict(read_dotenv('.env'))\n",
    "openai.api_key = dotenv['OPENAI_TOKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede36217",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a44e90d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16dabe3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p data/sources/alpaca\n",
    "!curl -L https://github.com/yizhongw/self-instruct/raw/main/human_eval/user_oriented_instructions.jsonl \\\n",
    "    > data/sources/alpaca/user_oriented_instructions.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fca385",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = read_jsonl('data/sources/alpaca/user_oriented_instructions.jsonl')\n",
    "alpaca_items = list(parse_alpaca(items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa473e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## vicuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16051ba",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p data/sources/vicuna\n",
    "!curl -L https://github.com/lm-sys/vicuna-blog-eval/raw/main/eval/table/question.jsonl \\\n",
    "    > data/sources/vicuna/question.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bffdeb3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = read_jsonl('data/sources/vicuna/question.jsonl')\n",
    "vicuna_items = list(parse_vicuna(items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b97d2c4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## arena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa10145c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!mkdir -p data/sources/arena\n",
    "!curl -L curl -L https://huggingface.co/datasets/lmsys/chatbot_arena_conversations/resolve/main/data/train-00000-of-00001-cced8514c7ed782a.parquet \\\n",
    "    > data/sources/arena/train-00000-of-00001-cced8514c7ed782a.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88246d9b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "records = pd.read_parquet('data/sources/arena/train-00000-of-00001-cced8514c7ed782a.parquet').itertuples()\n",
    "arena_items = list(parse_arena(records))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c177f80",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42507178",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "orig_items = alpaca_items + vicuna_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f73172",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "instruction_items = {\n",
    "    _['instruction']: _\n",
    "    for _ in arena_items\n",
    "    if _['lang'] == 'English'\n",
    "}\n",
    "orig_items.extend(random.sample(list(instruction_items.values()), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672928a8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "write_jsonl('data/orig.jsonl', orig_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62b37138",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '6711af7d-4165-45e2-a45e-755c4eca5026',\n",
       "  'source': 'arena',\n",
       "  'source_id': '1ad24688c2a545e4b40be8c8f0129a8f',\n",
       "  'lang': 'English',\n",
       "  'instruction': 'convert movie to emoji : midnight express, shinning'},\n",
       " {'id': '418214b0-fdb9-4634-ad50-0701b1bab193',\n",
       "  'source': 'arena',\n",
       "  'source_id': 'ca5b0426f2ab48f6b0a82ddeace44480',\n",
       "  'lang': 'English',\n",
       "  'instruction': 'can you create me 3 music band name with that acronym: DIK and give a description'},\n",
       " {'id': '4d5561ff-d153-4f84-8def-8d15525e0013',\n",
       "  'source': 'alpaca',\n",
       "  'source_id': 'user_oriented_task_67',\n",
       "  'instruction': 'You should choose a YouTube video title based on the video\\'s content. A video\\'s title tells viewers what to expect from it. It should be direct, honest, and clear. The title of the video needs to capture the attention of viewers, so do not use an unclear or ambiguous one.\\n\\n\"A research study has been conducted to determine if exercise really can \"boost\" your metabolism.\"'},\n",
       " {'id': 'e96d61ad-7d3a-4fbf-b2b4-6709e51ecdbd',\n",
       "  'source': 'arena',\n",
       "  'source_id': 'c2c53cb3b033412998ac0f0a8a4d98ab',\n",
       "  'lang': 'English',\n",
       "  'instruction': 'What is the lowest number that contains the letter c.'},\n",
       " {'id': '7f17669f-4fa9-432e-9d21-cd32b640f3d4',\n",
       "  'source': 'vicuna',\n",
       "  'source_id': 48,\n",
       "  'category': 'fermi',\n",
       "  'instruction': 'How many pages are in all the books ever written? Try to explain your answer. Your explanation should take the reader through your reasoning step-by-step.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_items = list(read_jsonl('data/orig.jsonl'))\n",
    "random.sample(orig_items, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2079d8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21013408",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "translate_items = [\n",
    "    {\n",
    "        'id': _['id'],\n",
    "        'instruction': _['instruction'],\n",
    "        'answer': None\n",
    "    }\n",
    "    for _ in orig_items\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27096d3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in translate_items if not _['answer']]\n",
    "queue = iter(tqdm(items))\n",
    "workers = [openai_translate_worker(queue) for _ in range(10)]\n",
    "await asyncio.gather(*workers);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f6cd2e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "write_jsonl('data/translate.jsonl', translate_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9159e5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# label studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a4d4d9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "label_studio = label_studio_sdk.Client('http://localhost:8080', dotenv['LABELSTUDIO_TOKEN'])\n",
    "label_studio.check_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac14092a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "title_projects = {\n",
    "    _.title: _\n",
    "    for _ in label_studio.list_projects()\n",
    "}\n",
    "translate_project = title_projects['translate']\n",
    "classify_project = title_projects['classify']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50978c8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# translate annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b4061",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "translate_items = read_jsonl('data/translate.jsonl')\n",
    "annot_items = [translate_annot_item(_) for _ in translate_items]\n",
    "random.choice(annot_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af21e7f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "translate_project.delete_all_tasks();\n",
    "translate_project.import_tasks(annot_items);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5763565",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "annot_items = translate_project.export_tasks()\n",
    "translate_items = [annot_translate_item(_) for _ in annot_items]\n",
    "random.sample(translate_items, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae799927",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "write_jsonl('data/translate.jsonl', translate_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cfb55e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263316d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "classify_items = list(read_jsonl('data/classify.jsonl'))\n",
    "id_embeddings = read_pickle('data/embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9e158",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [\n",
    "    _ for _ in classify_items\n",
    "    if _['id'] not in id_embeddings\n",
    "]\n",
    "for index in tqdm(range(0, len(items), 64)):\n",
    "    batch = items[index:index + 64]\n",
    "    texts = [_['instruction'] for _ in batch]\n",
    "    embeddings = openai_embed_batch(texts)\n",
    "    for item, embedding in zip(batch, embeddings):\n",
    "        id_embeddings[item['id']] = np.array(embedding)\n",
    "write_pickle('data/embeddings.pkl', id_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24754a41",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_items = [\n",
    "    _ for _ in classify_items\n",
    "    if _['tags'] and 'bad instruction' not in _['tags']\n",
    "]\n",
    "items = [_ for _ in classify_items if not _['tags']]\n",
    "\n",
    "for item in tqdm(items):\n",
    "    max_sim = 0\n",
    "    for target_item in target_items:\n",
    "        sim = cosine_sim(\n",
    "            id_embeddings[item['id']],\n",
    "            id_embeddings[target_item['id']]\n",
    "        )\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            item['tags'] = target_item['tags']\n",
    "    item['max_sim'] = max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320535ad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "items = []\n",
    "for item in classify_items:\n",
    "    if not item.get('max_sim'):\n",
    "        continue\n",
    "        \n",
    "    if 'enumerate' not in item['tags']:\n",
    "        continue\n",
    "        \n",
    "    items.append(item)\n",
    "\n",
    "items = sorted(items, key=lambda _: _['max_sim'], reverse=False)\n",
    "annot_items = [classify_annot_item(_) for _ in items]\n",
    "len(annot_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562d1120",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classify_project.delete_all_tasks();\n",
    "classify_project.import_tasks(annot_items);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061f33e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "annot_items = classify_project.export_tasks()\n",
    "items = (annot_classify_item(_) for _ in annot_items)\n",
    "id_tags = {\n",
    "    _['id']: _['tags']\n",
    "    for _ in items\n",
    "}\n",
    "for item in classify_items:\n",
    "    tags = id_tags.get(item['id'])\n",
    "    if tags is not None:\n",
    "        item['tags'] = tags\n",
    "        item.pop('max_sim', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e51a7b4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for item in classify_items:\n",
    "    if item.pop('max_sim', None):\n",
    "        item['tags'] = []\n",
    "write_jsonl('data/classify.jsonl', classify_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cd2b67",
   "metadata": {},
   "source": [
    "# tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b3e243f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "551"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = read_jsonl('data/classify.jsonl')\n",
    "id_tags = {_['id']: _['tags'] for _ in items if _['tags']}\n",
    "len(id_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17b2c1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1317"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = read_jsonl('data/orig.jsonl')\n",
    "id_sources = {_['id']: _['source'] for _ in items}\n",
    "len(id_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b4b690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_items = []\n",
    "items = read_jsonl(f'data/translate.jsonl')\n",
    "for item in items:\n",
    "    id = item['id']\n",
    "    tags = id_tags.get(id, [])\n",
    "    if 'bad instruction' in tags:\n",
    "        continue\n",
    "\n",
    "    task_items.append({\n",
    "        'id': id,\n",
    "        'source': id_sources[id],\n",
    "        'instruction': item['answer'],\n",
    "        'tags': tags\n",
    "    })\n",
    "write_jsonl(f'data/tasks.jsonl', task_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f538cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_items = list(read_jsonl('data/tasks.jsonl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e063e32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "source_items = defaultdict(list)\n",
    "for item in task_items:\n",
    "    source_items[item['source']].append(item)\n",
    "\n",
    "with open('data/tasks.md', 'w') as file:\n",
    "    with redirect_stdout(file):\n",
    "        for source in ['alpaca', 'vicuna', 'arena']:\n",
    "            print(f'<h1>{source}</h1>')\n",
    "\n",
    "            items = [_ for _ in source_items[source] if _['tags']]\n",
    "            for item in random.sample(items, 30):\n",
    "                print(' '.join(f'<code>#{_}</code>' for _ in item['tags']))\n",
    "                print('<br/>')\n",
    "                instruction = html.escape(item['instruction'])\n",
    "                print('<br/>\\n'.join(instruction.splitlines()))\n",
    "                print('<br/><br/>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110788d",
   "metadata": {},
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "360ba33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "infer_items = list(read_jsonl('data/infer.jsonl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fa4fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_items.extend(\n",
    "    {\n",
    "        'id': _['id'],\n",
    "        'model': 'gigachat',\n",
    "        'instruction': _['instruction'],\n",
    "        'answer': None\n",
    "    }\n",
    "    for _ in task_items\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eabeb706",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl('data/infer.jsonl', infer_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a3efedd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|items| = 360\n",
      "Регулярное выражение (Regex) представляет собой набор символов, которые определяют шаблон поиска. Этот тип шаблона обычно используется алгоритмами поиска в строке для поиска или замены строк или для проверки входных данных. Преобразуйте естественный текст на английском языке в регулярное выражение.\n",
      "\n",
      "\"Проверить что строка - IP-адрес\"\n",
      "----\n",
      "Для преобразования естественного текста на английском языке в регулярное выражение можно использовать следующее выражение: \n",
      "\n",
      "<code>^(?!.*\\b[0-9]{1,3}\\b\\.){3}[0-9]{1,3}$</code>\n",
      "\n",
      "Это регулярное выражение проверяет, что строка начинается с одного или нескольких допустимых символов (например, `^`, `$`, `*`, `+`, `(`, `)`, `|`), за которыми следует один или несколько допустимых символов (например, `\\b`, `[`, `]`, `{`, `}`), а затем может следовать любой другой допустимый символ (например, `.`, `?`, `;`, `:`). \n",
      "\n",
      "Таким образом, это регулярное выражение проверяет, что строка не содержит недопустимых символов и состоит только из допустимых символов.\n",
      "---\n",
      "\n",
      "\n",
      "Напиши от первого лица рассказ служанки, недовольной стиркой для дома Уиндзоров после того, как они провели день на верховой езде.\n",
      "----\n",
      "Я была очень недовольна тем, что мне пришлось заниматься стиркой для дома Уиндзоров после того, как мы провели целый день на верховой прогулке. Я уже устала от бесконечных поездок и хотела просто отдохнуть. Но вместо этого мне пришлось стирать все эти ужасные пятна с одежды и убирать конюшни. Я чувствовала себя так, будто я рабыня, а не служанка.\n",
      "---\n",
      "\n",
      "\n",
      "Предложите рецепт веганского десерта.\n",
      "----\n",
      "Для приготовления веганского десерта вам понадобятся свежие фрукты и ягоды, такие как клубника, малина, черника, голубика и т.д., а также кокосовая стружка или другие орехи для украшения. Сначала нарежьте фрукты на кусочки и смешайте их с кокосовой стружкой. Затем выложите полученную смесь в форму для выпечки и запекайте в духовке при температуре 180 градусов до золотистого цвета. Готовый десерт можно украсить свежими ягодами сверху.\n",
      "---\n",
      "\n",
      "\n",
      "Если у меня было 4 яблока, и я съел половину одного из них, сколько яблок у меня осталось?\n",
      "----\n",
      "У вас осталось 3 яблока.\n",
      "---\n",
      "\n",
      "\n",
      "Простыми словами объясни мне, как работают языковые модели?\n",
      "----\n",
      "Языковые модели — это программы, которые могут генерировать текст на основе обучающих данных. Они состоят из двух частей: генеративной (построчной) и предобученной (предсказательной). Генеративная часть модели использует правила для создания новых слов и фраз, а предобученная часть модели использует эти слова и фразы для предсказания следующего слова или фразы в тексте.\n",
      "---\n",
      "\n",
      "\n",
      "Перечислите несколько популярных песен из данного альбома.\n",
      "\n",
      "\"Back To Black\"\n",
      "----\n",
      "1. \"Back to Black\"\n",
      "2. \"Stairway to Heaven\"\n",
      "3. \"Highway to Hell\"\n",
      "4. \"Let It Be\"\n",
      "---\n",
      "\n",
      "\n",
      "Опишите обязанности, связанные с данной работой.\n",
      "\n",
      "\"Сотрудник службы безопасности\"\n",
      "----\n",
      "Обязанности, связанные с данной работой, могут включать следующее:\n",
      "— Проверка документов и личных данных посетителей;\n",
      "— Контроль за соблюдением правил безопасности на объекте;\n",
      "— Обеспечение сохранности имущества компании;\n",
      "— Мониторинг оперативной обстановки и выявление потенциальных угроз для бизнеса;\n",
      "— Разработка и реализация мер по предотвращению краж, мошенничества и других преступлений.\n",
      "---\n",
      "\n",
      "\n",
      "Данному тексту необходимо присвоить тег \"оскорбительный\" или \"неоскорбительный\":\n",
      "\n",
      "\"Ты вел себя действительно безумно вчера вечером.\"\n",
      "----\n",
      "Оскорбительный\n",
      "---\n",
      "\n",
      "\n",
      "Звездочкой в тексте пометил пропущенное слово. Приведи несколько примеров какие слова можно использовать вместо звездочки.\n",
      "\n",
      "\"нам * знать\"\n",
      "----\n",
      "Вместо звездочки можно использовать следующие слова:\n",
      "— знать\n",
      "— понимать\n",
      "— осознавать\n",
      "— видеть\n",
      "— слышать\n",
      "— ощущать\n",
      "---\n",
      "\n",
      "\n",
      "Тебе следует внимательно изучить ситуацию и проблему и дать наилучший совет, который можешь предложить.\n",
      "\n",
      "\"Я путешествую по Новой Зеландии вместе с другом, и он сводит меня с ума. Он не наслаждается всеми экскурсиями, на которые мы ходили, и не хочет болтать ни о чем. Он постоянно носит наушники в машине и в гостинице - не то чтобы я старался с ним разговаривать. Честно говоря, его негативная энергетика портит все и разрушает мою поездку. У нас пока нет ничего запланировано для Южного острова, поэтому я планирую оставить его в Веллингтоне перед посадкой на паром. Скорее всего, я сделаю бронь на собственное авто в Пиктоне и просто буду наслаждаться одиночеством в остальной части поездки. (Подумать об этом приносит такое облегчение, что я чувствую эмоциональное возбуждение. Я заплачу любую цену, лишь бы уйти от него.)\n",
      "Очевидно, что просто сказать ему, что он испортил мою поездку своей отрицательной энергетикой, не является лучшим способом решить проблему.\n",
      "Есть ли совет по лучшему подходу, чтобы мы могли расстаться мирно? Или хотя бы не спорить и не ранить друг друга глубоко?\"\n",
      "----\n",
      "Как генеративная языковая модель, я не могу лично общаться с людьми или иметь личные отношения. Однако, я могу дать некоторые общие советы, которые могут помочь вам решить эту ситуацию.\n",
      "\n",
      "Во-первых, важно понимать, что каждый человек имеет право на свое личное пространство и время для себя. Попробуйте уважать это право вашего друга и не беспокоить его без необходимости. Если вы чувствуете, что ваше присутствие мешает ему наслаждаться поездкой, то может быть хорошей идеей предложить ему остаться в Веллингтоне перед посадкой на паром.\n",
      "\n",
      "Однако, если вы хотите сохранить дружеские отношения, то можете попробовать найти компромиссное решение. Например, вы можете договориться о том, чтобы разделить экскурсии поровну между вами или же выбрать те места, которые больше нравятся вам обоим. Важно помнить, что никто не должен чувствовать себя нежеланным или игнорируемым.\n",
      "\n",
      "Также стоит учитывать возможные последствия вашей ситуации для вас обоих. Возможно, вам будет полезно провести некоторое время отдельно друг от друга, чтобы отдохнуть и переоценить свои отношения. Это поможет вам избежать конфликтов и сохранить здоровые отношения.\n",
      "\n",
      "В конечном итоге, лучший способ решить эту ситуацию — это открытый и честный разговор между вами. Вы можете обсудить свои чувства и желания, а также выслушать точку зрения вашего друга. Может быть, есть какое-то решение, которое устроит всех вас и сохранит ваши отношения.\n",
      "---\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items = [_ for _ in infer_items if _['model'] == 'gigachat' and _['answer'] is not None]\n",
    "print('|items| =', len(items))\n",
    "\n",
    "random.shuffle(items)\n",
    "for item in items[:10]:\n",
    "    if item['answer']:\n",
    "        print(item['instruction'])\n",
    "        print('----')\n",
    "        print(item['answer'])\n",
    "        print('---\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d4a6de",
   "metadata": {},
   "source": [
    "## turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in infer_items if _['answer'] is None and _['model'] == 'turbo_2']\n",
    "queue = iter(tqdm(items))\n",
    "workers = [openai_infer_worker(queue, model='gpt-3.5-turbo-0613') for _ in range(20)]\n",
    "await asyncio.gather(*workers);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f22277",
   "metadata": {},
   "source": [
    "## gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b109b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in infer_items if _['answer'] is None and _['model'] == 'gpt4_2']\n",
    "queue = iter(tqdm(items))\n",
    "workers = [openai_infer_worker(queue, model='gpt-4-0613', request_timeout=120) for _ in range(20)]\n",
    "await asyncio.gather(*workers);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5423d065",
   "metadata": {},
   "source": [
    "# gigachat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1924575",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "headers = dict(read_headers('.gigachat'))\n",
    "gigachat = gigachat_client(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After ~5 min / 360 answers blocked for ~1 hour\n",
    "# {'result': 'rejected', 'reason': 'UserBlocked', 'user_blocked_until': '2023-08-25T11:00:24+00:00'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cddeace",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in infer_items if _['answer'] is None and _['model'] == 'gigachat']\n",
    "queue = iter(tqdm(items))\n",
    "workers = [gigachat_infer_worker(gigachat, queue) for _ in range(5)]\n",
    "await asyncio.gather(*workers);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0986f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rulm-sbs2",
   "language": "python",
   "name": "rulm-sbs2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
