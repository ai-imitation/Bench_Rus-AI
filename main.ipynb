{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3562acb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "dotenv = dict(read_dotenv('.env'))\n",
    "openai.api_key = dotenv['OPENAI_TOKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69d9d73",
   "metadata": {},
   "source": [
    "# sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc7f856",
   "metadata": {},
   "source": [
    "## alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117b70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/sources/alpaca\n",
    "!curl -L https://github.com/yizhongw/self-instruct/raw/main/human_eval/user_oriented_instructions.jsonl \\\n",
    "    > data/sources/alpaca/user_oriented_instructions.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d972d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = read_jsonl('data/sources/alpaca/user_oriented_instructions.jsonl')\n",
    "alpaca_items = list(parse_alpaca(items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd74fbc5",
   "metadata": {},
   "source": [
    "## vicuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88bc076",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/sources/vicuna\n",
    "!curl -L https://github.com/lm-sys/vicuna-blog-eval/raw/main/eval/table/question.jsonl \\\n",
    "    > data/sources/vicuna/question.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afca9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = read_jsonl('data/sources/vicuna/question.jsonl')\n",
    "vicuna_items = list(parse_vicuna(items))\n",
    "random.sample(vicuna_items, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fb52a6",
   "metadata": {},
   "source": [
    "## arena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e2e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/sources/arena\n",
    "!curl -L curl -L https://huggingface.co/datasets/lmsys/chatbot_arena_conversations/resolve/main/data/train-00000-of-00001-cced8514c7ed782a.parquet \\\n",
    "    > data/sources/arena/train-00000-of-00001-cced8514c7ed782a.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9e93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "records = pd.read_parquet('data/sources/arena/train-00000-of-00001-cced8514c7ed782a.parquet').itertuples()\n",
    "arena_items = list(parse_arena(records))\n",
    "random.sample(arena_items, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb7782a",
   "metadata": {},
   "source": [
    "# orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182feb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_items = alpaca_items + vicuna_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8330b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_items = {\n",
    "    _['instruction']: _\n",
    "    for _ in arena_items\n",
    "    if _['lang'] == 'English'\n",
    "}\n",
    "orig_items.extend(random.sample(list(instruction_items.values()), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce33c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl('data/orig.jsonl', orig_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f84465d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '6711af7d-4165-45e2-a45e-755c4eca5026',\n",
       "  'source': 'arena',\n",
       "  'source_id': '1ad24688c2a545e4b40be8c8f0129a8f',\n",
       "  'lang': 'English',\n",
       "  'instruction': 'convert movie to emoji : midnight express, shinning'},\n",
       " {'id': '418214b0-fdb9-4634-ad50-0701b1bab193',\n",
       "  'source': 'arena',\n",
       "  'source_id': 'ca5b0426f2ab48f6b0a82ddeace44480',\n",
       "  'lang': 'English',\n",
       "  'instruction': 'can you create me 3 music band name with that acronym: DIK and give a description'},\n",
       " {'id': '4d5561ff-d153-4f84-8def-8d15525e0013',\n",
       "  'source': 'alpaca',\n",
       "  'source_id': 'user_oriented_task_67',\n",
       "  'instruction': 'You should choose a YouTube video title based on the video\\'s content. A video\\'s title tells viewers what to expect from it. It should be direct, honest, and clear. The title of the video needs to capture the attention of viewers, so do not use an unclear or ambiguous one.\\n\\n\"A research study has been conducted to determine if exercise really can \"boost\" your metabolism.\"'},\n",
       " {'id': 'e96d61ad-7d3a-4fbf-b2b4-6709e51ecdbd',\n",
       "  'source': 'arena',\n",
       "  'source_id': 'c2c53cb3b033412998ac0f0a8a4d98ab',\n",
       "  'lang': 'English',\n",
       "  'instruction': 'What is the lowest number that contains the letter c.'},\n",
       " {'id': '7f17669f-4fa9-432e-9d21-cd32b640f3d4',\n",
       "  'source': 'vicuna',\n",
       "  'source_id': 48,\n",
       "  'category': 'fermi',\n",
       "  'instruction': 'How many pages are in all the books ever written? Try to explain your answer. Your explanation should take the reader through your reasoning step-by-step.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_items = list(read_jsonl('data/orig.jsonl'))\n",
    "random.sample(orig_items, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa92a2c",
   "metadata": {},
   "source": [
    "# translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65faee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_items = [\n",
    "    {\n",
    "        'id': _['id'],\n",
    "        'instruction': _['instruction'],\n",
    "        'answer': None\n",
    "    }\n",
    "    for _ in orig_items\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in translate_items if not _['answer']]\n",
    "queue = iter(tqdm(items))\n",
    "workers = [openai_translate_worker(queue) for _ in range(10)]\n",
    "await asyncio.gather(*workers);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40efc64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl('data/translate.jsonl', translate_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288fbc75",
   "metadata": {},
   "source": [
    "# label studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef69df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "label_studio = label_studio_sdk.Client('http://localhost:8080', dotenv['LABELSTUDIO_TOKEN'])\n",
    "label_studio.check_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06a98b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_projects = {\n",
    "    _.title: _\n",
    "    for _ in label_studio.list_projects()\n",
    "}\n",
    "translate_project = title_projects['translate']\n",
    "classify_project = title_projects['classify']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989d6d5a",
   "metadata": {},
   "source": [
    "# translate annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863afdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_items = read_jsonl('data/translate.jsonl')\n",
    "annot_items = [translate_annot_item(_) for _ in translate_items]\n",
    "random.choice(annot_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4efc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_project.delete_all_tasks();\n",
    "translate_project.import_tasks(annot_items);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_items = translate_project.export_tasks()\n",
    "translate_items = [annot_translate_item(_) for _ in annot_items]\n",
    "random.sample(translate_items, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16196d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl('data/translate.jsonl', translate_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b531ef",
   "metadata": {},
   "source": [
    "# classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bac245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "classify_items = list(read_jsonl('data/classify.jsonl'))\n",
    "id_embeddings = read_pickle('data/embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79d2bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [\n",
    "    _ for _ in classify_items\n",
    "    if _['id'] not in id_embeddings\n",
    "]\n",
    "for index in tqdm(range(0, len(items), 64)):\n",
    "    batch = items[index:index + 64]\n",
    "    texts = [_['instruction'] for _ in batch]\n",
    "    embeddings = openai_embed_batch(texts)\n",
    "    for item, embedding in zip(batch, embeddings):\n",
    "        id_embeddings[item['id']] = np.array(embedding)\n",
    "\n",
    "write_pickle('data/embeddings.pkl', id_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0907f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_items = [\n",
    "    _ for _ in classify_items\n",
    "    if _['tags'] and 'bad instruction' not in _['tags']\n",
    "]\n",
    "items = [_ for _ in classify_items if not _['tags']]\n",
    "\n",
    "for item in tqdm(items):\n",
    "    max_sim = 0\n",
    "    for target_item in target_items:\n",
    "        sim = cosine_sim(\n",
    "            id_embeddings[item['id']],\n",
    "            id_embeddings[target_item['id']]\n",
    "        )\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            item['tags'] = target_item['tags']\n",
    "    item['max_sim'] = max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491fcc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "for item in classify_items:\n",
    "    if not item.get('max_sim'):\n",
    "        continue\n",
    "        \n",
    "    if 'enumerate' not in item['tags']:\n",
    "        continue\n",
    "        \n",
    "    items.append(item)\n",
    "\n",
    "items = sorted(items, key=lambda _: _['max_sim'], reverse=False)\n",
    "annot_items = [classify_annot_item(_) for _ in items]\n",
    "len(annot_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60eb59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_project.delete_all_tasks();\n",
    "classify_project.import_tasks(annot_items);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5ef17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "annot_items = classify_project.export_tasks()\n",
    "items = (annot_classify_item(_) for _ in annot_items)\n",
    "id_tags = {\n",
    "    _['id']: _['tags']\n",
    "    for _ in items\n",
    "}\n",
    "for item in classify_items:\n",
    "    tags = id_tags.get(item['id'])\n",
    "    if tags is not None:\n",
    "        item['tags'] = tags\n",
    "        item.pop('max_sim', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efd70a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in classify_items:\n",
    "    if item.pop('max_sim', None):\n",
    "        item['tags'] = []\n",
    "\n",
    "write_jsonl('data/classify.jsonl', classify_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ffde2",
   "metadata": {},
   "source": [
    "# tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3580114d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "551"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = read_jsonl('data/classify.jsonl')\n",
    "id_tags = {_['id']: _['tags'] for _ in items if _['tags']}\n",
    "len(id_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f3e539b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1317"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = read_jsonl('data/orig.jsonl')\n",
    "id_sources = {_['id']: _['source'] for _ in items}\n",
    "len(id_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79d0f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_items = []\n",
    "items = read_jsonl(f'data/translate.jsonl')\n",
    "for item in items:\n",
    "    id = item['id']\n",
    "    tags = id_tags.get(id, [])\n",
    "    if 'bad instruction' in tags:\n",
    "        continue\n",
    "\n",
    "    task_items.append({\n",
    "        'id': id,\n",
    "        'source': id_sources[id],\n",
    "        'instruction': item['answer'],\n",
    "        'tags': tags\n",
    "    })\n",
    "write_jsonl(f'data/tasks.jsonl', task_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1be9cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_items = list(read_jsonl('data/tasks.jsonl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf18088f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "source_items = defaultdict(list)\n",
    "for item in task_items:\n",
    "    source_items[item['source']].append(item)\n",
    "\n",
    "with open('data/README.md', 'w') as file:\n",
    "    with redirect_stdout(file):\n",
    "        for source in ['alpaca', 'vicuna', 'arena']:\n",
    "            print(f'<h1>{source}</h1>')\n",
    "\n",
    "            items = [_ for _ in source_items[source] if _['tags']]\n",
    "\n",
    "            for item in random.sample(items, 30):\n",
    "                print(' '.join(f'<code>#{_}</code>' for _ in item['tags']))\n",
    "                print('<br/>')\n",
    "                instruction = html.escape(item['instruction'])\n",
    "                print('<br/>\\n'.join(instruction.splitlines()))\n",
    "                print('<br/><br/>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37dae83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rulm-sbs2",
   "language": "python",
   "name": "rulm-sbs2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
