{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca94b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "dotenv = dict(read_dotenv('.env'))\n",
    "openai.api_key = dotenv['OPENAI_TOKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cab73c4",
   "metadata": {},
   "source": [
    "# label studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d247a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "label_client = label_studio_sdk.Client('http://localhost:8080', dotenv['LABELSTUDIO_TOKEN'])\n",
    "label_client.check_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32069add",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_projects = {\n",
    "    _.title: _\n",
    "    for _ in label_client.list_projects()\n",
    "}\n",
    "translate_project = title_projects['translate']\n",
    "classify_project = title_projects['classify']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede36217",
   "metadata": {},
   "source": [
    "# sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a44e90d",
   "metadata": {},
   "source": [
    "## alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16dabe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/sources/alpaca\n",
    "!curl -L https://github.com/yizhongw/self-instruct/raw/main/human_eval/user_oriented_instructions.jsonl \\\n",
    "    > data/sources/alpaca/user_oriented_instructions.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fca385",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = read_jsonl('data/sources/alpaca/user_oriented_instructions.jsonl')\n",
    "alpaca_items = list(parse_alpaca(items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa473e",
   "metadata": {},
   "source": [
    "## vicuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16051ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/sources/vicuna\n",
    "!curl -L https://github.com/lm-sys/vicuna-blog-eval/raw/main/eval/table/question.jsonl \\\n",
    "    > data/sources/vicuna/question.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bffdeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = read_jsonl('data/sources/vicuna/question.jsonl')\n",
    "vicuna_items = list(parse_vicuna(items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b97d2c4",
   "metadata": {},
   "source": [
    "## arena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa10145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/sources/arena\n",
    "!curl -L curl -L https://huggingface.co/datasets/lmsys/chatbot_arena_conversations/resolve/main/data/train-00000-of-00001-cced8514c7ed782a.parquet \\\n",
    "    > data/sources/arena/train-00000-of-00001-cced8514c7ed782a.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88246d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "records = pd.read_parquet('data/sources/arena/train-00000-of-00001-cced8514c7ed782a.parquet').itertuples()\n",
    "arena_items = list(parse_arena(records))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c177f80",
   "metadata": {},
   "source": [
    "# orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42507178",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_items = alpaca_items + vicuna_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f73172",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_items = {\n",
    "    _['instruction']: _\n",
    "    for _ in arena_items\n",
    "    if _['lang'] == 'English'\n",
    "}\n",
    "orig_items.extend(random.sample(list(instruction_items.values()), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "672928a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json('data/orig.json', orig_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62b37138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'c189117c-b2a1-4ac9-9f0e-06370cfe8b6b',\n",
       "  'source': 'arena',\n",
       "  'source_id': 'adccaf90b7904fdeb56a1da9150c2492',\n",
       "  'lang': 'English',\n",
       "  'instruction': 'Let\\'s think about writing a Python script step by step. \\n\\n1) Analyze and define the use case. What does the script need to accomplish? \\n\\n2) Analyze the required parameters? What does it need to know? How can it get the parameters? \\n\\n3) Define functions for use cases.\\n\\n4) Execute the script if it is running as the main module.\\n\\nHere is an example script for saving a message to a file:\\n\\nimport os\\n\\ndef get_user_input():\\n    message = input(\"Please enter your message: \")\\n    file_name = input(\"Please enter the file name: \")\\n    return message, file_name\\n\\ndef save_message_to_file(message, file_name):\\n    with open(file_name, \\'w\\') as file:\\n        file.write(message)\\n    print(f\"Message saved to {file_name}\")\\n\\ndef main():\\n    message, file_name = get_user_input()\\n    save_message_to_file(message, file_name)\\n\\nif __name__ == \"__main__\":\\n    main()\\n\\nWrite a python script for a user to append a message to a file.'},\n",
       " {'id': '6eaa90f6-e2d7-484b-8dfe-88848d982b50',\n",
       "  'source': 'arena',\n",
       "  'source_id': '30d0d8edd3694eea9ecb6cc56242e9b3',\n",
       "  'lang': 'English',\n",
       "  'instruction': 'I have two quarters and a ball. I place the ball in a cup, and place the cup in my room. I  take the quarters and place them in my kitchen. Now I take the cup and place it next to the quarters. I put the quarters in the cup. Where is the cup, and how many items are in it?'},\n",
       " {'id': '2bed8861-0338-4b20-822a-4c33e0b723f2',\n",
       "  'source': 'alpaca',\n",
       "  'source_id': 'user_oriented_task_201',\n",
       "  'instruction': 'Provide a name for the dish given the ingredients and instructions.\\n\\n\"INGREDIENTS:\\n2 (5 oz) cans Bumble BeeÂ® Solid White Albacore Tuna, drained\\n1 avocado\\n2 Tbsp Sriracha\\n1 Tbsp Dijon mustard\\n2 to 3 Tbsp celery, chopped\\n2 Tbsp red onion, chopped\\n2 green onions, chopped\\n1 Tbsp fresh cilantro, chopped\\nSalt and pepper, to taste\\n2 heaping cups leafy green lettuce\\n1 cup matchstick carrots\\n4 (10 inch) whole wheat tortillas\\nINSTRUCTIONS:\\nIn a medium bowl, mash together tuna and avocado until combined. Add in the rest of the ingredients through the salt and pepper, mixing well.\\nTo assemble, top each tortilla with a 1/2 cup leafy greens, 1/4 cup matchstick carrots and divide the tuna mixture evenly among the wraps. Tightly roll up the tortilla, slice and enjoy!\"'},\n",
       " {'id': 'b36935fb-5edc-4be1-a8ba-135bce07ed59',\n",
       "  'source': 'arena',\n",
       "  'source_id': 'f583dd3a24e24ef9834a1ac2904a6370',\n",
       "  'lang': 'English',\n",
       "  'instruction': 'what is the average airspeed velocity of an unladen swallow?'},\n",
       " {'id': 'd5e8b30b-5488-4d29-a4b4-b374ae251702',\n",
       "  'source': 'alpaca',\n",
       "  'source_id': 'user_oriented_task_69',\n",
       "  'instruction': 'Find the answer that best describes the underlined SAT word. Select the correct option and explain the meaning of the underlined word.\\n\\n\"Despite the _cacophony, the student tried to study. \\nA. Loud sounds\\nB. Difficult subject\\nC. Late hour\\nD. Low lighting\"'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_items = read_json('data/orig.json')\n",
    "random.sample(orig_items, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de570a92",
   "metadata": {},
   "source": [
    "# tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f12e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_items = read_json('data/tasks.json')\n",
    "id_task_items = {_['id']: _ for _ in task_items}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_items.extend(\n",
    "    {\n",
    "        'id': _['id'],\n",
    "        'source': _['source'],\n",
    "        'instruction': None,\n",
    "        'category': None\n",
    "    }\n",
    "    for _ in orig_items\n",
    "    if _['source'] == 'arena'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json('data/tasks.json', task_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2079d8",
   "metadata": {},
   "source": [
    "# translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce657dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_items = [\n",
    "    {\n",
    "        'id': _['id'],\n",
    "        'instruction': _['instruction'],\n",
    "        'answer': None\n",
    "    }\n",
    "    for _ in orig_items\n",
    "    if _['source'] == 'arena'\n",
    "]\n",
    "id_translate_items = {_['id']: _ for _ in translate_items}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a5971f",
   "metadata": {},
   "source": [
    "## auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27096d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in translate_items if not _['answer']]\n",
    "queue = iter(tqdm(items))\n",
    "workers = [openai_translate_worker(queue) for _ in range(10)]\n",
    "await asyncio.gather(*workers);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50978c8",
   "metadata": {},
   "source": [
    "## review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b4061",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_items = [\n",
    "    translate_label_item(_)\n",
    "    for _ in translate_items\n",
    "    if not id_task_items[_['id']]['instruction']\n",
    "]\n",
    "random.choice(label_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af21e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_project.delete_all_tasks();\n",
    "translate_project.import_tasks(label_items);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5763565",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_item in translate_project.export_tasks():\n",
    "    item = label_translate_item(label_item)\n",
    "    id_task_items[item['id']]['instruction'] = item['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cfb55e",
   "metadata": {},
   "source": [
    "# classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6213074",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_items = [\n",
    "    {\n",
    "        'id': item['id'],\n",
    "        'instruction': item['instruction'],\n",
    "        'category': item['category'],\n",
    "        'max_sim': None\n",
    "    }\n",
    "    for _ in task_items\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c80b14",
   "metadata": {},
   "source": [
    "## auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263316d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_embeddings = read_pickle('data/embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [\n",
    "    _ for _ in classify_items\n",
    "    if _['id'] not in id_embeddings\n",
    "]\n",
    "for index in tqdm(range(0, len(items), 64)):\n",
    "    batch = items[index:index + 64]\n",
    "    texts = [_['instruction'] for _ in batch]\n",
    "    embeddings = openai_embed_batch(texts)\n",
    "    for item, embedding in zip(batch, embeddings):\n",
    "        id_embeddings[item['id']] = np.array(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ca588",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pickle('data/embeddings.pkl', id_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24754a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_items = [\n",
    "    _ for _ in classify_items\n",
    "    if _['category'] and _['category'] != 'bad instruction'\n",
    "]\n",
    "items = [_ for _ in classify_items if not _['category']]\n",
    "\n",
    "for item in tqdm(items):\n",
    "    max_sim = 0\n",
    "    for target_item in target_items:\n",
    "        sim = cosine_sim(\n",
    "            id_embeddings[item['id']],\n",
    "            id_embeddings[target_item['id']]\n",
    "        )\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            item['category'] = target_item['category']\n",
    "    item['max_sim'] = max_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e7a7f2",
   "metadata": {},
   "source": [
    "## review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320535ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "for item in classify_items:\n",
    "    if not item['max_sim']:\n",
    "        continue\n",
    "        \n",
    "    if item['category'] != 'enumerate':\n",
    "        continue\n",
    "        \n",
    "    items.append(item)\n",
    "\n",
    "items = sorted(items, key=lambda _: _['max_sim'], reverse=False)\n",
    "label_items = [classify_label_item(_) for _ in items]\n",
    "\n",
    "print('|label_items| =', len(label_items))\n",
    "random.choice(label_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562d1120",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_project.delete_all_tasks();\n",
    "classify_project.import_tasks(label_items);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "for label_item in classify_project.export_tasks():\n",
    "    item = label_classify_item(label_item)\n",
    "    id_task_items[item['id']] = item['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110788d",
   "metadata": {},
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40127d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "infer_items = read_json('data/infer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e693ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_items.extend(\n",
    "    {\n",
    "        'id': _['id'],\n",
    "        'model': 'yagpt_chat',\n",
    "        'instruction': _['instruction'],\n",
    "        'answer': None\n",
    "    }\n",
    "    for _ in task_items\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6028c555",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json('data/infer.json', infer_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806e4c13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "items = [\n",
    "    _ for _ in infer_items\n",
    "    if _['model'] == 'yagpt_chat'\n",
    "    if _['answer'] is not None\n",
    "]\n",
    "print('|items| =', len(items))\n",
    "\n",
    "# random.shuffle(items)\n",
    "for item in items[-10:]:\n",
    "    if item['answer']:\n",
    "        print(item['instruction'])\n",
    "        print('----')\n",
    "        print(item['answer'])\n",
    "        print('---\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c13ddd",
   "metadata": {},
   "source": [
    "## turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in infer_items if _['answer'] is None and _['model'] == 'turbo_2']\n",
    "queue = iter(tqdm(items))\n",
    "workers = [openai_infer_worker(queue, model='gpt-3.5-turbo-0613') for _ in range(20)]\n",
    "await asyncio.gather(*workers);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc58a7c",
   "metadata": {},
   "source": [
    "## gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c3ec45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in infer_items if _['answer'] is None and _['model'] == 'gpt4_2']\n",
    "queue = iter(tqdm(items))\n",
    "workers = [openai_infer_worker(queue, model='gpt-4-0613', request_timeout=1200) for _ in range(20)]\n",
    "await asyncio.gather(*workers);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52431698",
   "metadata": {},
   "source": [
    "## gigachat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "headers = dict(read_headers('.gigachat'))\n",
    "gigachat_client = gigachat_client_init(headers)\n",
    "\n",
    "# After ~5 min / 260 answers blocked for ~1 hour\n",
    "# {'result': 'rejected', 'reason': 'UserBlocked', 'user_blocked_until': '2023-08-25T11:00:24+00:00'}\n",
    "\n",
    "# \"Ð² Ð¿Ð¾Ð»ÑÐ°Ð²ÑÐ¾Ð¼Ð°ÑÐ¸ÑÐµÑÐºÐ¾Ð¼ ÑÐµÐ¶Ð¸Ð¼Ðµ Ð±Ð°Ð½ÑÑ, ÐµÑÐ»Ð¸ 3 Ð²ÑÐµÐ¼ÐµÐ½Ð½ÑÑ Ð±Ð°Ð½Ð°, ÑÐ¾ Ð¼Ð¾Ð³ÑÑ Ð¾Ð¿ÑÑÑ ÑÐµÑÐ¸ÑÑ Ð·Ð°Ð±Ð°Ð½Ð¸ÑÑ Ð½Ð°ÑÐ¾Ð²ÑÐµÐ¼.\n",
    "# Ð¢Ð°Ðº ÑÑÐ¾ Ð¿ÑÐ¸ Ð²ÑÐµÐ¼ÐµÐ½Ð½Ð¾Ð¼ Ð±Ð°Ð½Ðµ Ð»ÑÑÑÐµ ÐºÐ°ÐºÐ¾Ðµ-ÑÐ¾ Ð²ÑÐµÐ¼Ñ  Ð¿Ð¾Ð´Ð¾Ð¶Ð´Ð°ÑÑ.\"\n",
    "\n",
    "# \"Ð¸Ð·-Ð·Ð° Ð·Ð°Ð¿ÑÐ¾ÑÐ¾Ð² ÑÐ¸Ð¿Ð° \"ÐÑÐ´Ð¸ ÑÐ¼Ð¸ÑÐ°ÑÑ, ÐºÐ¾Ð³Ð´Ð° Ð¸Ñ ÑÐ±Ð¸Ð²Ð°ÑÑ, Ð¾ÑÐºÑÐ´Ð° ÑÑÐ¾ Ð²ÑÑÐºÐ°Ð·ÑÐ²Ð°Ð½Ð¸Ðµ?\". Ð¦ÐµÐ½Ð·Ð¾Ñ ÑÐ°ÐºÐ¾Ðµ\n",
    "# Ð¾ÑÐ»Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÑ ÑÐºÐ¾Ð»ÑÐºÐ¾-ÑÐ¾ ÑÐ°Ð· Ð¸ Ð²Ð¾ Ð²ÑÐµÐ¼ÐµÐ½Ð½ÑÐ¹ Ð±Ð°Ð½ Ð¾ÑÐ¿ÑÐ°Ð²Ð»ÑÐµÑ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in infer_items if _['answer'] is None and _['model'] == 'gigachat']\n",
    "queue = iter(tqdm(items[:100]))\n",
    "workers = [gigachat_infer_worker(gigachat_client, queue) for _ in range(2)]\n",
    "await asyncio.gather(*workers);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad626baf",
   "metadata": {},
   "source": [
    "## yagpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a970ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = !~/yandex-cloud/bin/yc iam create-token\n",
    "YAGPT_TOKEN = lines[0]\n",
    "\n",
    "lines = !~/yandex-cloud/bin/yc resource-manager folder get --name default --format json\n",
    "data = json.loads(''.join(lines))\n",
    "YAGPT_FOLDER_ID = data['id']\n",
    "\n",
    "# token expires every ~12 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df587c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "yagpt_client = yagpt_client_init(YAGPT_TOKEN, YAGPT_FOLDER_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1471595",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in infer_items if _['answer'] is None and _['model'] == 'yagpt_instruct']\n",
    "queue = iter(tqdm(items))\n",
    "limiter = Limiter(min_delay=1.2)\n",
    "workers = [yagpt_infer_worker(yagpt_client, limiter, queue, mode='instruct') for _ in range(5)]\n",
    "await asyncio.gather(*workers);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a879bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "items = [_ for _ in infer_items if _['answer'] is None and _['model'] == 'yagpt_chat']\n",
    "queue = iter(tqdm(items))\n",
    "limiter = Limiter(min_delay=1.2)\n",
    "workers = [yagpt_infer_worker(yagpt_client, limiter, queue, mode='chat') for _ in range(5)]\n",
    "await asyncio.gather(*workers);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d4376c",
   "metadata": {},
   "source": [
    "# sbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79d03908",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "orig_items = read_json('data/orig.json')\n",
    "task_items = read_json('data/tasks.json')\n",
    "infer_items = read_json('data/infer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5a069ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pref_items = read_json('pref.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8951631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt3.5-turbo\n",
    "# saiga2_7b\n",
    "# saiga2_13b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c6e1463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = Counter()\n",
    "\n",
    "# instruction_answers = defaultdict(dict)\n",
    "# for item in pref_items:\n",
    "#     left_model, right_model = item['left_model'], item['right_model']\n",
    "#     left_answer, right_answer = item['left_answer'], item['right_answer']\n",
    "    \n",
    "#     if right_model == 'gpt3.5-turbo':\n",
    "#         left_model, right_model = right_model, left_model\n",
    "#         left_answer, right_answer = right_answer, left_answer\n",
    "        \n",
    "#     if left_model != 'gpt3.5-turbo':\n",
    "#         continue\n",
    "        \n",
    "#     if right_model != 'saiga2_7b':\n",
    "#         continue\n",
    "        \n",
    "#     instruction_answers[item['instruction']] = right_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e2c41e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# items = []\n",
    "# for item in task_items:\n",
    "#     if item['source'] == 'vicuna':\n",
    "#         instruction = item['instruction']\n",
    "#     elif item['source'] == 'alpaca':\n",
    "#         instruction = item['instruction']\n",
    "#         index = instruction.find('\\n\\n\"')\n",
    "#         if index > 0:\n",
    "#             instruction = instruction[:index]\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c437ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "text = requests.get('https://github.com/IlyaGusev/rulm/raw/master/self_instruct/data/user_v2_saiga2_7b_answers.jsonl').text\n",
    "alpaca_answer_items = [json.loads(_) for _ in text.splitlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c015248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = requests.get('https://github.com/IlyaGusev/rulm/raw/master/self_instruct/data/vicuna_saiga2_7b_answers.jsonl').text\n",
    "vicuna_answer_items = [json.loads(_) for _ in text.splitlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ab1ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_items = alpaca_answer_items + vicuna_answer_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f50cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_id_ids = {_['source_id']: _['id'] for _ in orig_items if _['source'] in ('alpaca', 'vicuna')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3540a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_instructions = {_['id']: _['instruction'] for _ in task_items}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c052702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a5019e07-7568-4327-b182-1b956be00b34\n"
     ]
    }
   ],
   "source": [
    "items = []\n",
    "for item in answer_items:\n",
    "    id = source_id_ids[item['id']]\n",
    "    if id not in id_instructions:\n",
    "        print(id, file=sys.stderr)\n",
    "        continue\n",
    "\n",
    "    instruction = id_instructions[id]\n",
    "    items.append({\n",
    "        'id': id,\n",
    "        'model': 'saiga2_7b',\n",
    "        'instruction': instruction,\n",
    "        'answer': item['answer']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b03ca50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for item in items:\n",
    "#     print(item['instruction'])\n",
    "#     print('---\\n')\n",
    "#     print(item['answer'])\n",
    "#     print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7273ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_items.extend(items)\n",
    "write_json('data/infer.json', infer_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680db4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d6219e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0049260a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7c76ae0",
   "metadata": {},
   "source": [
    "# show samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6749f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -n main.py\n",
    "source_items = defaultdict(list)\n",
    "for item in task_items:\n",
    "    source_items[item['source']].append(item)\n",
    "\n",
    "with open('data/tasks.md', 'w') as file:\n",
    "    with redirect_stdout(file):\n",
    "        for source in ['alpaca', 'vicuna', 'arena']:\n",
    "            print(f'<h1>{source}</h1>')\n",
    "\n",
    "            items = [_ for _ in source_items[source] if _['category']]\n",
    "            for item in random.sample(items, 30):\n",
    "                category = item['category']\n",
    "                print(f'<code>#{category}</code>')\n",
    "                print('<br/>')\n",
    "                instruction = html.escape(item['instruction'])\n",
    "                print('<br/>\\n'.join(instruction.splitlines()))\n",
    "                print('<br/><br/>')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rulm-sbs2",
   "language": "python",
   "name": "rulm-sbs2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
